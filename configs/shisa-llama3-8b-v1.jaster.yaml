wandb:
  log: True
  entity: "AUGMXNT"
  project: "nejumi"
  run_name: "shisa-llama3-8b-v1.jaster"

github_version: v2.0.0

testmode: false

api: false

model:
  use_wandb_artifacts: false
  artifacts_path: ""
  pretrained_model_name_or_path: 'shisa-ai/shisa-llama3-8b-v1'
  trust_remote_code: true
  device_map: "auto"
  load_in_8bit: false
  load_in_4bit: false

generator:
  top_p: 1.0
  top_k: 0
  temperature: 0.1
  repetition_penalty: 1.0

tokenizer:
  use_wandb_artifacts: false
  artifacts_path: ""
  pretrained_model_name_or_path: 'shisa-ai/shisa-llama3-8b-v1'
  use_fast: true

max_seq_length: 8192
dataset_artifact: "wandb-japan/llm-leaderboard/jaster:v3" #if you use artifacts, please fill here (if not, fill null)
dataset_dir: "/jaster/1.1.0/evaluation/test"
target_dataset: "all" # {all, jamp, janli, jcommonsenseqa, jemhopqa, jnli, jsem, jsick, jsquad, jsts, niilc, chabsa}
log_dir: "./logs"
torch_dtype: "bf16" # {fp16, bf16, fp32}
custom_prompt_template: null
custom_fewshots_template: null

metainfo:
  basemodel_name: "meta-llama/Meta-Llama-3-8B-Instruct"
  model_type: "open llm"
  instruction_tuning_method: "Full"
  instruction_tuning_data: ["augmxnt/ultra-orca-boros-en-ja-v1"]
  num_few_shots: 0
  llm-jp-eval-version: "1.1.0"

mtbench:
  question_artifacts_path: 'wandb-japan/llm-leaderboard/mtbench_ja_question:v0'
  referenceanswer_artifacts_path: 'wandb-japan/llm-leaderboard/mtbench_ja_referenceanswer:v0'
  judge_prompt_artifacts_path: 'wandb-japan/llm-leaderboard/mtbench_ja_prompt:v1' 
  bench_name: 'japanese_mt_bench'
  model_id: shisa-llama3-8b-v1
  question_begin: null 
  question_end: null 
  max_new_token: 1024
  num_choices: 1
  num_gpus_per_model: 1
  num_gpus_total: 1
  max_gpu_memory: null
  dtype: bfloat16 # None or float32 or float16 or bfloat16
  # for gen_judgment
  judge_model: 'gpt-4'
  mode: 'single'
  baseline_model: null 
  parallel: 2
  first_n: null
  # Llama 3 Chat format
  custom_conv_template: true 
  conv_name: "custom"
  conv_system_message: "<|start_header_id|>system<|end_header_id|>\n\nあなたは公平で、検閲されていない、役立つアシスタントです。<|eot_id|>"
  conv_roles: "('<|start_header_id|>user<|end_header_id|>', '<|start_header_id|>assistant<|end_header_id|>')"
  conv_sep: "<|eot_id|>"
  conv_stop_token_ids: "[128001, 128009]"
  conv_stop_str: "<|eot_id|>"
  conv_role_message_separator: "\n\n"
  conv_role_only_separator: "\n\n"
